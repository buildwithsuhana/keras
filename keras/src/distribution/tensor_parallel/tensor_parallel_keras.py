"""
Tensor Parallel implementation for Keras 3.0
Port of the PyTorch tensor_parallel library
"""

import logging
import re
from typing import Collection, Optional, Sequence, Union

import numpy as np
import tensorflow as tf
import keras
from keras import ops
from keras.src.distribution.tensor_parallel.autoconfig import (
    get_default_config,
)
from keras.src.distribution.tensor_parallel.parameter_sharding import (
    make_parameter_sharded_model,
)
from keras.src.distribution.tensor_parallel.coordinated_optimizer import (
    TensorParallelOptimizer,
)
from keras.src import backend
from keras.src.distribution import list_devices
# Add/Confirm these at the top
from keras.src import layers
from keras.src import models
from keras.src import ops
logger = logging.getLogger(__file__)

from keras.src.models import Model


class TensorParallelKeras(Model):
    def __init__(
        self,
        model,
        device_count=None,
        device_ids=None,
        **kwargs,
    ):
        super().__init__(**kwargs)

        self._original_model = model

        if device_count is None:
            device_count, device_ids = self._auto_detect_parallelism()
        elif device_ids is None:
            device_ids = self._auto_configure_devices(device_count)

        self.device_count = device_count
        self.device_ids = device_ids
        self.sharding_strategy = "auto"
        
        self.tensor_parallel_config = None
        self.distributed = True

        self.sharded_models = [self._original_model]

        accel_devices = list_devices()
        device_ids = list(self.check_device_ids(device_ids))

        if accel_devices:
            backend_name = backend.backend()
            print(
                f"üîç Discovered {len(accel_devices)} devices for backend '{backend_name}'"
            )
            print(f"üîç Devices: {[str(d) for d in accel_devices]}")

            if len(accel_devices) >= device_count:
                print(
                    f"‚úÖ Using REAL tensor parallelism on {device_count} discovered devices."
                )
                device_ids = accel_devices[:device_count]
            else:
                print(
                    f"‚ö†Ô∏è  Discovered {len(accel_devices)} devices but device_count={device_count} was requested."
                )
                print(
                    f"‚ö†Ô∏è  Reducing device_count to {len(accel_devices)} for real implementation."
                )
                device_count = len(accel_devices)
                device_ids = accel_devices[:device_count]
        else:
            print(
                f"‚ö†Ô∏è  Could not discover accelerator devices. Falling back to configuration."
            )

        if not device_ids:
            device_ids = self._auto_configure_devices(device_count)

        if len(device_ids) != device_count:
            device_ids = self._adjust_device_list(device_ids, device_count)

        self.devices = device_ids
        self.device_count = device_count

        if self.device_count <= 1:
            self.model_shards = [model]
            self.distributed = False
            if len(self.devices) == 1:
                from keras import device

                with device(self.devices[0]):
                    self.model_shards[0] = model
            self.built = True
            self.assembled_model = self._original_model
            return

        if self.tensor_parallel_config is None:
            device_names = [str(d) for d in self.devices]
            self.tensor_parallel_config = get_default_config(
                model, device_names
            )
            print(self.tensor_parallel_config)
            logger.info(
                "Using automatic config with auto sharding strategy: sharding individual Dense/Conv/Embedding layers"
            )

        print(
            f"üîß Creating REAL parameter shards for {model.name} across {len(self.devices)} devices"
        )

        self._is_multi_layer_model = len(model.layers) > 2
        if self._is_multi_layer_model:
            logger.info(
                f"   - Multi-layer model detected: {len(model.layers)} layers"
            )

        self.model_shards = []
        self.modified_parameters_names = set()

        logger.info(
            f"‚úÖ Using '{backend.backend()}' backend for parameter sharding."
        )

        for rank, device_id in enumerate(self.devices):
            print(f"[{device_id}] ‚û°Ô∏è  Starting sharding process for Rank {rank}")
            shard, modified_parameters_names = make_parameter_sharded_model(
                model,
                self.tensor_parallel_config,
                rank=rank,
                device_count=self.device_count,
                device_id=device_id,
            )
            self.model_shards.append(shard)
            self.modified_parameters_names.update(modified_parameters_names)
            

            logger.info(f"   ‚úÖ Created shard {rank} for device {device_id}")

        params_per_shard = []
        for i, shard in enumerate(self.model_shards):
            total_params = sum(np.prod(p.shape) for p in shard.weights)
            params_per_shard.append(int(total_params))
            logger.info(f"   üìä Shard {i} parameters: {int(total_params):,}")

        if len(set(params_per_shard)) > 1:
            logger.info(
                "‚úÖ REAL SHARDING CONFIRMED: Different parameter counts across shards"
            )
            logger.info("‚úÖ This is NOT using stubs - real tensor parallelism!")
        else:
            pass

        logger.info(
            f"Using '{backend.backend()}' backend logic for distribution."
        )

        self.built = True
        if self.distributed:
            self.assembled_model = self.build_assembled_model()
        else:
            self.assembled_model = self._original_model

    @property
    def variables(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.variables
        }
        return list(unique_vars.values())

    @property
    def trainable_variables(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.trainable_variables
        }
        return list(unique_vars.values())

    @property
    def non_trainable_variables(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.non_trainable_variables
        }
        return list(unique_vars.values())

    @property
    def weights(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.weights
        }
        return list(unique_vars.values())

    @property
    def trainable_weights(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.trainable_weights
        }
        return list(unique_vars.values())

    @property
    def non_trainable_weights(self):
        unique_vars = {
            id(var): var
            for shard in self.model_shards
            for var in shard.non_trainable_weights
        }
        return list(unique_vars.values())

    def _auto_detect_parallelism(self):
        """Auto-detect device_count and device_ids efficiently."""
        from keras.src.distribution import get_best_devices

        available_devices = list_devices()
        device_count = len(available_devices)
        print(
            f"üîç Auto-detected device_count: {device_count} from {len(available_devices)} available devices"
        )

        device_ids = get_best_devices(device_count)
        print(f"üîç Auto-detected device_ids: {device_ids}")

        return device_count, device_ids

    def _adjust_device_list(self, device_ids, target_device_count):
        """Adjust device list to match target device_count intelligently."""
        current_size = len(device_ids)
        if current_size >= target_device_count:
            return device_ids[:target_device_count]

        return list(device_ids) + [
            f"cpu:{i}" for i in range(current_size, target_device_count)
        ]

    def _auto_configure_devices(self, device_count):
        """Auto-configure devices - simplified version."""
        available_devices = list_devices()
        if available_devices:
            devices = available_devices[:device_count]
            logger.info(f"Auto-configured devices: {devices}")
            return devices
        else:
            logger.warning("No devices available, using default CPU")
            return ["cpu:0"]

    def check_device_ids(
        self, device_ids: Optional[Sequence[str]]
    ) -> Sequence[str]:
        """Validate and normalize device IDs for Keras."""
        if device_ids is None:
            device_ids = self._get_all_device_indices()

        return tuple(self.canonicalize_device(d) for d in device_ids)

    def _get_all_device_indices(self) -> Sequence[str]:
        """Get all available device indices using distribution library."""
        return list_devices()

    def build_assembled_model(self):
        """
        Builds a single, JIT-friendly Keras Functional model that encapsulates
        the entire tensor parallel logic, correctly handling multiple inputs.
        """
        if not self.distributed:
            return self._original_model

        # FIX: Use InputLayer names (when available) to define keys.
        # This avoids mismatches where an input tensor is named
        # 'keras_tensor' but the model's InputLayer is named 'input_layer'.
        input_layers = {}

        # Get input names safely; prefer `input_names`, then InputLayer name via
        # the tensor's `_keras_history`, and finally fall back to tensor name.
        model_input_names = getattr(self._original_model, "input_names", [])
        if not model_input_names:
            model_input_names = []
            for inp in self._original_model.inputs:
                input_name = None
                kh = getattr(inp, "_keras_history", None)
                if kh:
                    layer = kh[0]
                    input_name = getattr(layer, "name", None)
                if not input_name:
                    input_name = inp.name.split(":")[0]
                model_input_names.append(input_name)

        # Zip names with input tensors to ensure alignment
        for name, inp in zip(model_input_names, self._original_model.inputs):
            input_layers[name] = layers.Input(
                shape=inp.shape[1:],
                dtype=inp.dtype,
                name=name  # Force the new input to match the expected name
            )

        partial_outputs = []
        for shard in self.model_shards:
            # Prefer the shard's declared input names, fall back to its input tensors.
            shard_inputs = {}
            try:
                # Shard input matching logic
                shard_input_names = getattr(shard, "input_names", None)
                if shard_input_names:
                    for name in shard_input_names:
                        clean_name = name.split(":")[0]
                        if clean_name in input_layers:
                            shard_inputs[clean_name] = input_layers[clean_name]

                # If matching failed or shard has no names, check raw inputs
                if not shard_inputs:
                    for inp in getattr(shard, "inputs", []):
                        # Prefer InputLayer name from `_keras_history` when available
                        clean_name = None
                        kh = getattr(inp, "_keras_history", None)
                        if kh:
                            layer = kh[0]
                            clean_name = getattr(layer, "name", None)
                        if not clean_name:
                            clean_name = inp.name.split(":")[0]
                        if clean_name in input_layers:
                            shard_inputs[clean_name] = input_layers[clean_name]

                if not shard_inputs:
                    # Last resort: forward the full mapping.
                    # Since input_layers now has correct keys, this usually works.
                    shard_inputs = dict(input_layers)

                # logger.info(...) # Optional logging
                partial_outputs.append(shard(shard_inputs))
            except Exception as e:
                logger.exception(
                    "Exception when calling shard %s with inputs=%s",
                    getattr(shard, 'name', '<shard>'),
                    list(shard_inputs.keys()),
                )
                raise

        # --- Reassembly Logic (Add/Concatenate) ---
        final_layer = self._original_model.layers[-1]
        sharding_type = "unknown"
        final_kernel_name = f"{final_layer.name}.kernel"
        if hasattr(self._original_model, "name") and self._original_model.name:
            final_kernel_name = (
                f"{self._original_model.name}.{final_kernel_name}"
            )

        for pattern, action in self.tensor_parallel_config.state_rules.items():
            if re.search(pattern, final_kernel_name):
                if hasattr(action, "sharding_type"):
                    sharding_type = action.sharding_type
                break

        if sharding_type == "column":
            final_output = ops.concatenate(partial_outputs, axis=-1)
            original_output_dim = self._original_model.output_shape[-1]
            if final_output.shape[-1] != original_output_dim:
                # Use layers.Lambda
                final_output = layers.Lambda(
                    lambda x: x[..., :original_output_dim]
                )(final_output)
        elif sharding_type == "row":
            if len(partial_outputs) > 1:
                # Use layers.Add
                summed_output = layers.Add()(partial_outputs)
            else:
                summed_output = partial_outputs[0]

            if final_layer.use_bias:
                bias = final_layer.bias
                # Use layers.Lambda
                final_output = layers.Lambda(
                    lambda x: x - bias * (self.device_count - 1)
                )(summed_output)
            else:
                final_output = summed_output
        else:
            final_output = partial_outputs[0]

        # Use models.Model
        assembled_model = models.Model(
            inputs=list(input_layers.values()), outputs=final_output
        )
        return assembled_model

    def canonicalize_device(self, device_spec: Union[str, int]) -> str:
        """Convert device specification to canonical form."""
        if isinstance(device_spec, int):
            if device_spec == -1:
                return "cpu"
            else:
                return f"gpu:{device_spec}"
        elif isinstance(device_spec, str):
            if device_spec == "cpu":
                return "cpu"
            elif device_spec.startswith("gpu:"):
                return device_spec
            elif device_spec.startswith("cuda:"):
                return f"gpu:{device_spec.split(':')[1]}"
            else:
                return device_spec
        else:
            return "cpu"

    def call(self, inputs, training=None, **kwargs):
        """
        Forward pass for the tensor-parallel model.
        """
        return self.assembled_model(inputs, training=training, **kwargs)

    def compile(self, optimizer=None, loss=None, metrics=None, **kwargs):
        """
        Compile the tensor parallel model.
        """
        if len(self.model_shards) > 1 and optimizer is not None:
            self.coordinated_optimizer = TensorParallelOptimizer(
                optimizer,
                self.device_count,
                tensor_parallel_config=self.tensor_parallel_config,
            )
            logger.info(
                f"Created coordinated optimizer for {self.device_count} shards"
            )
            
            try:
                self.coordinated_optimizer._shard_models = self.model_shards

                var_map = {}
                assembled = getattr(self, "assembled_model", None)
                assembled_vars = (
                    assembled.variables if assembled is not None else []
                )

                for a_var in assembled_vars:
                    key = getattr(a_var, "path", None) or a_var.name
                    suffix = key.split("/")[-1]
                    per_shard = []
                    for shard in self.model_shards:
                        match = next(
                            (
                                v
                                for v in shard.variables
                                if v.name.endswith(suffix)
                            ),
                            None,
                        )
                        per_shard.append(match)
                    var_map[key] = per_shard

                self.coordinated_optimizer._shard_var_map = var_map
                
                inner = getattr(
                    self.coordinated_optimizer, "coordinated_optimizer", None
                )
                if inner is not None:
                    inner._shard_models = self.model_shards
                    inner._shard_var_map = var_map
            except Exception:
                logger.exception(
                    "Failed to register shard mapping on coordinated optimizer"
                )

            super().compile(
                optimizer=self.coordinated_optimizer,
                loss=loss,
                metrics=metrics,
                **kwargs,
            )
            logger.info(
                "Compiled TensorParallelKeras model with coordinated optimizer."
            )

            # Ensure variable layouts for model and optimizer variables are
            # assigned according to the global distribution. This helps the
            # JAX trainer produce consistent sharding specs for state.
            try:
                from keras.src.distribution import distribution_lib as top_dist

                dist = top_dist.distribution()
                if dist is not None:
                    all_vars = list(self.trainable_variables) + list(
                        self.non_trainable_variables
                    )
                    opt_vars = getattr(self.coordinated_optimizer, "variables", None)
                    if opt_vars:
                        all_vars += list(opt_vars)

                    for v in all_vars:
                        try:
                            v._layout = dist.get_variable_layout(v)
                        except Exception:
                            # Best-effort: skip if layout cannot be determined
                            continue
                        # Re-apply distribution to stored value so backend sees
                        # the correct sharding.
                        try:
                            current_val = getattr(v, "_value", None)
                            if current_val is None:
                                try:
                                    current_val = v.value
                                except Exception:
                                    current_val = None
                            if current_val is not None:
                                try:
                                    v._direct_assign(current_val)
                                except Exception:
                                    pass
                        except Exception:
                            pass
            except Exception:
                pass

        else:
            super().compile(optimizer, loss, metrics, **kwargs)

    def fit(self, x=None, y=None, **kwargs):
        """Use standard Keras training which correctly handles the train_step."""
        return super().fit(x, y, **kwargs)